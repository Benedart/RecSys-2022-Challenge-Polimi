************************ MODELS ************************ 

SLIM Elastic:	
				
{*vanilla urm*					|*urm 2.0*				|urm 2.0 + stacking (alpha=0.5633154480471164)
    "topK": 6468,				|bonus: +0.2, malus: 0			|bonus: 0.25, fake malus: 0.15, real malus: 0
    "l1_ratio": 0.03534306561986866,		|'topK': 3054 				|topK: 2026
    "alpha": 0.001,				|l1_ratio': 0.04424799535913358		|l1_ratio: 0.10985234148570669
}						|alpha = 0.0011635794316003463		|alpha: 0.0001258298378771297
MAP (train+validation): 0.027753		|MAP (train+validation): 0.027851	|MAP (train+validation): 0.027928
------------------------------------------------+---------------------------------------+---------------------------------------+
						|					|					|
RP3Beta:					|bonus: 0.75, malus: 0			|					|
topK= 63					|topK= 50				|					|
alpha= 0.6828387166323279			|alpha= 0.8552186583443476		|					|
beta= 0.2930220842625131			|beta= 0.3382669103515696		|					|
normalize_similarity= True			|normalize_similarity= True		|					|
MAP (train+validation): 0.025603		|MAP (train+validation): 0.025854	|					|
------------------------------------------------+---------------------------------------+---------------------------------------+
						|
ItemKNN_CFCBF:					|
{						|
    'ICM_weight': 0.7942705620438129,		|
    'topK': 57,					|
    'shrink': 46,				|
    'similarity': 'asymmetric',			|
    'asymmetric_alpha': 1.0078079911435072,	|
    'normalize': True,				|
    'feature_weighting': 'BM25',		|
    'ICM_bias': 0.05378471200597431		|
}						|
MAP (train+validation): 0.024628		|
------------------------------------------------+---------------------------------------+---------------------------------------+
						|
UserKNN:					|
{						|
    'topK': 570,				|
    'shrink': 197,				|
    'similarity': 'asymmetric',			|
    'asymmetric_alpha': 0.5016128296674885,	|
    'normalize': True,				|
    'feature_weighting': 'BM25',		|
    'URM_bias': 71.84496171909362		|
}						|
MAP (train+validation): 0.024389		|
------------------------------------------------+---------------------------------------+---------------------------------------+
						|
SLIM BPR:					|
topK= 18, 					|
epochs= 450, 					|
symmetric= False, 				|
sgd_mode= "adagrad", 				|
lambda_i= 0.00028544929663750347, 		|
lambda_j= 0.01, 				|
learning_rate= 0.1				|
MAP (train+validation): 0.022948		|
						|
------------------------------------------------+---------------------------------------+---------------------------------------+
						|
IALS:						|
{						|
    'epochs': 25 (36) (36),			|
    'num_factors': 86,				|
    'alpha': 5.024961505795806,			|
    'epsilon': 0.3208262245960988,		|
    'reg': 0.46509664550837687			|
    std_deviation = 1 / math.sqrt(factors) * 0.1|
}						|
MAP (train+validation): 0.019924 (0.019815??) (0.019961)
						|
------------------------------------------------+---------------------------------------+---------------------------------------+


************************ HYBRID ************************ 

Bonus/Malus:
SLIM 0.25 | 0.2 | 0
RP3 0.75 | 0 | 0
Ials 0 | 0 | 0

Weights:
hybrid = GeneralizedLinearHybridRecommender(urm_train_validation, [SlimE, RP3, ials])
hybrid.fit([2.057629061768366, 1.558966879154469, 0.08476762363426302])

MAP (train+validation): 0.028179

Bonus/Malus:
SLIM 0.25 | 0.15 | 0 + stacking
RP3 0.75 | 0 | 0
Ials 0 | 0 | 0

Weights:
'slim_weight': 1.8888069225803399,
 'rp3_weight': 0.6951792429618135,
 'ials_weight': 0.04684711158163043

hybrid = GeneralizedLinearHybridRecommender(urm_train_validation, [SlimE, RP3, ials])
MAP (train+validation): 0.028246



************************ XGBOOST ************************ 

Best Cutoff: 35 (forse)

n_estimators = 1000
learning_rate = 0.19823429576094637
reg_alpha = 47
reg_lambda = 0.313
max_depth = 3
max_leaves = 0
grow_policy = "depthwise"
objective = "pairwise"
booster = "gbtree"
use_user_profile = False
random_seed = None
colsample_bytree = 0.6113704247857885
gamma = 8.964184693722684
min_child_weight = 7.0

Added features: 
Hybrid
SLIM_Elastic
RP3Beta
ItemKNN_CFCBF
UserKNN
IALS
Item pop - User profile length - type (1-hot) - length
